{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_zVfYjanWGWq"
   },
   "source": [
    "Twoim zadaniem jest wytrenowanie klasyfikatora binarnego na podzbiorze zbioru MNIST, w którym wyróżniamy klasy (cyfry 0 i 1 mają zostać wyłączone ze zbioru):\n",
    " - Liczby pierwsze (2,3,5,7)\n",
    " - Liczby złożone (4,6,8,9)\n",
    "\n",
    "Napisz wydajną implementację modelu **regresji logistycznej** trenowanego algorytmem ***SGD z momentum***. Cały proces trenowania musisz napisać samodzielnie, w języku Python, korzystając z biblioteki numpy. Na potrzeby zadania niedozwolone jest korzystanie z gotowych implementacji optimizerów i modeli oraz bibliotek do automatycznego różniczkowania funkcji (np. Tensorflow, pytorch, autograd). \n",
    "\n",
    "Dobierz hiperparametry tak, aby uzyskać jak najlepszy wynik na zbiorze walidacyjnym. \n",
    "Wyciągnij i zapisz wnioski z przeprowadzonych eksperymentów.\n",
    "\n",
    "Zbiór MNIST dostępny jest pod linkami: \n",
    "\n",
    "(zbiór treningowy):\n",
    " - http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
    " - http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
    "\n",
    "(zbiór walidacyjny):\n",
    " - http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
    " - http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Przygotowanie danych\n",
    "Zostają utworzone cztery macierze, dwie służące do trenowania modelu, oraz pozostałe dwie do jego walidacji. Następnie dane w macierzach z klasami zostają zamienione na 1 dla liczb pierwszych, 0 dla liczb złożonych, -1 dla 0 lub 1. Na koniec usuwane są wszystkie komórki zawierające -1 oraz odpowiadający im wektor w macierzach wejścia. Aby proces przebiegł poprawnie archiwa ze zbiorem MNIST muszą znajdować się w tym samym folderze co ten notatnik."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41386, 784)\n",
      "(41386, 1)\n"
     ]
    }
   ],
   "source": [
    "IMAGE_SIZE = 28\n",
    "\n",
    "validation_image = gzip.open(\".\\\\t10k-images-idx3-ubyte.gz\", \"r\")\n",
    "validation_labels = gzip.open(\".\\\\t10k-labels-idx1-ubyte.gz\", \"r\")\n",
    "\n",
    "train_image = gzip.open(\".\\\\train-images-idx3-ubyte.gz\", \"r\")\n",
    "train_labels = gzip.open(\".\\\\train-labels-idx1-ubyte.gz\", \"r\")\n",
    "\n",
    "validation_image.read(16)\n",
    "validation_labels.read(8)\n",
    "train_image.read(16)\n",
    "train_labels.read(8)\n",
    "\n",
    "def is_prime(x):\n",
    "    if x in [2,3,5,7]:\n",
    "        return 1\n",
    "    elif x in [4,6,8]:\n",
    "        return 0 \n",
    "    return -1\n",
    "\n",
    "is_prime = np.vectorize(is_prime)\n",
    "\n",
    "def generate_matrices(buffer, length):\n",
    "    M = np.frombuffer(buffer, dtype=np.uint8)\n",
    "    M = M.reshape(int(M.shape[0]/(length**2)), -1)\n",
    "\n",
    "    return M\n",
    "\n",
    "def generate_map(labels):\n",
    "    map = np.argwhere(labels == -1)\n",
    "    return map.T[0]\n",
    "\n",
    "\n",
    "X = generate_matrices(train_image.read(), IMAGE_SIZE)\n",
    "y = is_prime(generate_matrices(train_labels.read(), 1))\n",
    "map = generate_map(y)\n",
    "\n",
    "X = np.delete(X, map, 0)\n",
    "y = np.delete(y, map, 0)\n",
    "\n",
    "\n",
    "\n",
    "v_X = generate_matrices(validation_image.read(), IMAGE_SIZE)\n",
    "v_y = is_prime(generate_matrices(validation_labels.read(), 1))\n",
    "map = generate_map(v_y)\n",
    "\n",
    "v_X = np.delete(v_X, map, 0)\n",
    "v_y = np.delete(v_y, map, 0)\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "W celu wytrenowania modelu będę maksymalizował funkcję celu zadaną wzorem $$J(\\Theta)=\\frac{1}{m}\\sum_{i=0}^m $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Htj5iNRhWgz6"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class Model:\n",
    "\n",
    "  def fit(self, X: np.ndarray, y: np.ndarray) -> None:\n",
    "    pass\n",
    "\n",
    "  def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "    pass\n",
    "\n",
    "  @staticmethod\n",
    "  def evaluate(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
    "    # calculate accuracy\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gdXcw0IZWlZ_"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Research_Engineer_Warszawa_i_Kraków",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
